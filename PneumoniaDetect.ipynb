{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PneumoniaDetect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-fes2Zjw5b9",
        "colab_type": "text"
      },
      "source": [
        "Add google disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGdGmTl-sKXm",
        "colab_type": "code",
        "outputId": "8ff2d46e-a238-4c08-ecc2-c5c28f00cafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-xgx4Qrqb3b",
        "colab_type": "text"
      },
      "source": [
        "Install the kaggle to system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsjkWsp7qGs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrhNQM9AtzQl",
        "colab_type": "text"
      },
      "source": [
        "Upload the kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy9AxfU_tyjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iu67x1et-pt",
        "colab_type": "text"
      },
      "source": [
        "Create the necessary folder path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iybWZQugt-yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AEp2ZHsqiF2",
        "colab_type": "text"
      },
      "source": [
        "Download the dataset from kaggle with API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvi5l-PrqkE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p /content/gdrive/My\\ Drive/pneumonia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is2b3sWYqlr2",
        "colab_type": "text"
      },
      "source": [
        "Unzip all files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5IjJAiLqntM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('gdrive/My Drive/pneumonia')\n",
        "!unzip -q chest-xray-pneumonia.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCfbjMEjMUAV",
        "colab_type": "text"
      },
      "source": [
        "To make sure Colab uses GPU you can run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVDkDXBqMT4u",
        "colab_type": "code",
        "outputId": "599e002e-375a-43ec-f728-4aea4c7faf61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q2S_WvhNppH",
        "colab_type": "text"
      },
      "source": [
        "Make sure that the current GPU memory utilization is 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qs6TSp7MnZa",
        "colab_type": "code",
        "outputId": "a394eeb2-254d-415c-f266-6dd131024936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.3 GB  | Proc size: 159.9 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD7lCjFMNzko",
        "colab_type": "text"
      },
      "source": [
        "If Util not 0% use kill"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GWVYD-uM3bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtJkcrhBqvAm",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXV2A0LiqzNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a753aeca-d55e-4f12-f8dd-c8dfe4decebe"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import applications, Sequential, Model, optimizers, models\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, History\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import h5py\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y20XxIFUq1DG",
        "colab_type": "text"
      },
      "source": [
        "Variables with train and test directories. \n",
        "Some constant variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2XmpPN4q2rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainInput = \"/content/gdrive/My Drive/pneumonia/chest_xray/chest_xray/train/\"\n",
        "testInput = \"/content/gdrive/My Drive/pneumonia/chest_xray/chest_xray/test/\"\n",
        "validationInput = \"/content/gdrive/My Drive/pneumonia/chest_xray/chest_xray/val/\"\n",
        "size = 199\n",
        "epochs = 3\n",
        "fileName = \"/content/gdrive/My Drive/pneumonia/images.h5\"\n",
        "modelsDir = \"/content/gdrive/My Drive/pneumonia/models/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDL1eym4q30E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extractData(directory):\n",
        "    labels = []\n",
        "    images = []\n",
        "\n",
        "    for nextDirectory in os.listdir(directory):\n",
        "        if not nextDirectory.startswith(\".\"):\n",
        "            if nextDirectory in \"NORMAL\":\n",
        "                label = 0\n",
        "            elif nextDirectory in \"PNEUMONIA\":\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 2\n",
        "\n",
        "            currentDirectory = directory + nextDirectory\n",
        "            if not currentDirectory.startswith(\".\"):\n",
        "                for files in tqdm(os.listdir(currentDirectory)):\n",
        "                    if files.endswith('.jpg') or files.endswith('.jpeg'):\n",
        "                        imagePath = currentDirectory + \"/\" + files\n",
        "                        img = Image.open(imagePath)\n",
        "                        img = img.resize((size, size)).convert(\"RGB\")\n",
        "                        data = np.array(img.getdata())\n",
        "                        img = 2 * (data.reshape((img.size[0], img.size[1], 3)).astype(np.float32) / 255) - 1\n",
        "                        images.append(img)\n",
        "                        labels.append(label)\n",
        "\n",
        "    labels = np.asarray(labels)\n",
        "\n",
        "    if directory == trainInput:\n",
        "        out = h5py.File(fileName, \"a\")\n",
        "        out.create_dataset(\"imagesTrain\", data=images)\n",
        "        out.create_dataset(\"labelsTrain\", data=labels)\n",
        "        out.close()\n",
        "    elif directory == testInput:\n",
        "        out = h5py.File(fileName, \"a\")\n",
        "        out.create_dataset(\"imagesTest\", data=images)\n",
        "        out.create_dataset(\"labelsTest\", data=labels)\n",
        "        out.close()\n",
        "    elif directory == validationInput:\n",
        "        out = h5py.File(fileName, \"a\")\n",
        "        out.create_dataset(\"imagesValidation\", data=images)\n",
        "        out.create_dataset(\"labelsValidation\", data=labels)\n",
        "        out.close()\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5SZ9s-IvZz5",
        "colab_type": "code",
        "outputId": "2e5aee94-9674-452f-ee1e-02bc29f695a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "extractData(trainInput)\n",
        "extractData(testInput)\n",
        "extractData(validationInput)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1342/1342 [09:05<00:00,  2.46it/s]\n",
            "100%|██████████| 3876/3876 [24:30<00:00,  2.64it/s]\n",
            "100%|██████████| 234/234 [01:33<00:00,  2.51it/s]\n",
            "100%|██████████| 390/390 [02:27<00:00,  2.64it/s]\n",
            "100%|██████████| 9/9 [00:00<00:00, 20.21it/s]\n",
            "100%|██████████| 9/9 [00:00<00:00, 25.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNA2rFbN9m1j",
        "colab_type": "text"
      },
      "source": [
        "Get the images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnTukdAeb0dL",
        "colab_type": "code",
        "outputId": "de7c2a03-5266-4eb4-b591-05539aa173c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = h5py.File(fileName, \"r\")[\"imagesTrain\"][:]\n",
        "print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5216, 199, 199, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdrcPl01q5KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dset = h5py.File(fileName, \"r\")\n",
        "labelsTrain, imagesTrain, labelsTest, imagesTest, labelsValidation, imagesValidation = dset[\"labelsTrain\"][:], dset[\"imagesTrain\"][:], dset[\"labelsTest\"][:], dset[\"imagesTest\"][:], dset[\"labelsValidation\"][:], dset[\"imagesValidation\"][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M81QETYCSSdf",
        "colab_type": "text"
      },
      "source": [
        "Reshape if fit_generator dont work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OavjTzoSTU2",
        "colab_type": "code",
        "outputId": "492575eb-ecce-4769-d468-e51f053e1c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "labelsTrain = to_categorical(labelsTrain, 2)\n",
        "labelsTest = to_categorical(labelsTest, 2)\n",
        "labelsValidation = to_categorical(labelsValidation, 2)\n",
        "print(\"Train:\", imagesTrain.shape, \"Test:\", imagesTest.shape, \"Validation:\", imagesValidation.shape)\n",
        "print(\"Train:\", labelsTrain.shape, \"Test:\", labelsTest.shape, \"Validation:\", labelsValidation.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (5216, 199, 199, 3) Test: (624, 199, 199, 3) Validation: (16, 199, 199, 3)\n",
            "Train: (5216, 2) Test: (624, 2) Validation: (16, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAo1519Ht-YQ",
        "colab_type": "text"
      },
      "source": [
        "Add an model, the weights can be none or imagenet. Imagenet is pre-trained on ImageNet.     \n",
        "include_top is set False in order to exclude the last three layers (including the final softmax layer with 200 classes of output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKxNKry6Fk6e",
        "colab_type": "text"
      },
      "source": [
        "This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n",
        "Reduce learning rate when a metric has stopped improving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTPxoU9Y0uZv",
        "colab_type": "text"
      },
      "source": [
        "Flatten() layer to flatten the tensor output. Dense is 2D layer which support the specification of their input shape. relu and softmax are different activations which used with layers, either can be used by activation layers. Activations: https://keras.io/activations/. Optimizers: https://keras.io/optimizers/. Losses: https://keras.io/losses/. Metrics: https://keras.io/metrics/. Compilation: https://keras.io/getting-started/sequential-model-guide/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AkYHdHbNvF0",
        "colab_type": "text"
      },
      "source": [
        "Measure time and creation of fit_generator: https://keras.io/models/model/#fit_generator , https://keras.io/models/model/#fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK0KrMa7QXFl",
        "colab_type": "text"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvphCiBO6XG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduceLearningRate = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, cooldown=2, min_lr=0.001, verbose=1)\n",
        "# reduceLearningRate = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1) \n",
        "earlyStop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "callbacks = [reduceLearningRate, earlyStop]\n",
        "\n",
        "def trainModel(model, name):\n",
        "  global history\n",
        "  pattern = model(weights='imagenet', include_top=False, input_shape=(size, size, 3))\n",
        "\n",
        "  addModel = Sequential()\n",
        "\n",
        "  addModel.add(Flatten(input_shape=pattern.output_shape[1:]))\n",
        "\n",
        "  addModel.add(Dense(256, activation='relu'))\n",
        "  addModel.add(Dense(128, activation='relu'))\n",
        "  addModel.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  md = Model(inputs=pattern.input, outputs=addModel(pattern.output))\n",
        "  md.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9), \n",
        "                  metrics=['accuracy'])\n",
        "  \n",
        "  history = md.fit(imagesTrain, labelsTrain, \n",
        "                   validation_data=(imagesTest, labelsTest),\n",
        "                   callbacks=callbacks, epochs=epochs)\n",
        "  \n",
        "  md.save(modelsDir + name + \".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyuzSVPr6mVH",
        "colab_type": "code",
        "outputId": "34d51c56-d989-4540-dca5-bf3583713600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "trainModel(applications.InceptionV3, \"InceptionV3\")\n",
        "trainModel(applications.Xception, \"Xception\")\n",
        "trainModel(applications.DenseNet201, \"DenseNet201\")\n",
        "trainModel(applications.InceptionResNetV2, \"InceptionResNetV2\")\n",
        "trainModel(applications.MobileNetV2, \"MobileNetV2\")\n",
        "trainModel(applications.VGG16, \"VGG16\")\n",
        "trainModel(applications.ResNet152V2, \"ResNet152V2\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5216 samples, validate on 624 samples\n",
            "Epoch 1/3\n",
            "5216/5216 [==============================] - 51s 10ms/step - loss: 0.3081 - accuracy: 0.8668 - val_loss: 0.6838 - val_accuracy: 0.7436\n",
            "Epoch 2/3\n",
            "5216/5216 [==============================] - 35s 7ms/step - loss: 0.1143 - accuracy: 0.9592 - val_loss: 0.6683 - val_accuracy: 0.7708\n",
            "Epoch 3/3\n",
            "5216/5216 [==============================] - 35s 7ms/step - loss: 0.0686 - accuracy: 0.9764 - val_loss: 0.5405 - val_accuracy: 0.8349\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Train on 5216 samples, validate on 624 samples\n",
            "Epoch 1/3\n",
            "5216/5216 [==============================] - 87s 17ms/step - loss: 0.2508 - accuracy: 0.8957 - val_loss: 0.5035 - val_accuracy: 0.7548\n",
            "Epoch 2/3\n",
            "5216/5216 [==============================] - 78s 15ms/step - loss: 0.1235 - accuracy: 0.9523 - val_loss: 0.6224 - val_accuracy: 0.7356\n",
            "Epoch 3/3\n",
            "5216/5216 [==============================] - 78s 15ms/step - loss: 0.0861 - accuracy: 0.9674 - val_loss: 0.5152 - val_accuracy: 0.7901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CamtYWuASxqC",
        "colab_type": "text"
      },
      "source": [
        "Load model and prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-70Pw2v1jDG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def global_test(dir_models, dir_test_image):\n",
        "\n",
        "    models_stat = []\n",
        "    num_mod = 0\n",
        "\n",
        "    labels = []\n",
        "    images = []\n",
        "\n",
        "    for nextDirectory in os.listdir(dir_test_image):\n",
        "        if not nextDirectory.startswith(\".\"):\n",
        "            if nextDirectory in \"NORMAL\":\n",
        "                label = 0\n",
        "            elif nextDirectory in \"PNEUMONIA\":\n",
        "                label = 1\n",
        "            else:\n",
        "                label = 2\n",
        "\n",
        "            currentDirectory = dir_test_image + nextDirectory\n",
        "            if not currentDirectory.startswith(\".\"):\n",
        "                for files in os.listdir(currentDirectory):\n",
        "                    if files.endswith('.jpg') or files.endswith('.jpeg'):\n",
        "                        imagePath = currentDirectory + \"/\" + files\n",
        "                        img = Image.open(imagePath)\n",
        "                        img = img.resize((size, size)).convert(\"RGB\")\n",
        "                        data = np.array(img.getdata())\n",
        "                        img = 2 * (data.reshape((img.size[0], img.size[1], 3)).astype(np.float32) / 255) - 1\n",
        "                        images.append(img)\n",
        "                        labels.append(label)\n",
        "\n",
        "    labels = np.asarray(labels)\n",
        "    average_accuracy = [0] * len(labels)\n",
        "\n",
        "    out = h5py.File(\"/content/gdrive/My Drive/pneumonia/tmptest.h5\", \"a\")\n",
        "    out.create_dataset(\"imagesTmp\", data=images)\n",
        "    out.close()\n",
        "\n",
        "    dset = h5py.File(\"/content/gdrive/My Drive/pneumonia/tmptest.h5\", \"r\")\n",
        "    imagesTmp = dset[\"imagesTmp\"][:]\n",
        "    os.remove(\"/content/gdrive/My Drive/pneumonia/tmptest.h5\")\n",
        "\n",
        "    for file_model in os.listdir(dir_models):\n",
        "        num_mod += 1\n",
        "\n",
        "        dir_model = dir_models + \"/\" + file_model\n",
        "        name = file_model[:-3]\n",
        "        model_stat = [name]\n",
        "    \n",
        "        model = models.load_model(dir_model)\n",
        "        predictions = model.predict(imagesTmp)\n",
        "        predictions = predictions.reshape(1, -1)[0]\n",
        "\n",
        "        accuracy_array = []\n",
        "\n",
        "        x = -1\n",
        "        for i in range(0, len(predictions), 2):\n",
        "            x += 1  \n",
        "            if predictions[i] > predictions[i + 1]:\n",
        "                if labels[x] == 0:\n",
        "                   accuracy_array.append(predictions[i])\n",
        "                   average_accuracy[x] += predictions[i]\n",
        "                else: \n",
        "                   accuracy_array.append(predictions[i + 1])  \n",
        "                   average_accuracy[x] += predictions[i + 1]\n",
        "\n",
        "            if predictions[i] < predictions[i + 1]:\n",
        "               if labels[x] == 1:\n",
        "                 accuracy_array.append(predictions[i + 1])\n",
        "                 average_accuracy[x] += predictions[i + 1]\n",
        "               else: \n",
        "                  accuracy_array.append(predictions[i])\n",
        "                  average_accuracy[x] += predictions[i]\n",
        "\n",
        "        model_stat.append(np.sum(accuracy_array) / len(accuracy_array) * 100)\n",
        "        models_stat.append(model_stat)\n",
        "        # print(model_stat)\n",
        "    for i in range(len(average_accuracy)):\n",
        "        average_accuracy[i] = average_accuracy[i] / num_mod\n",
        "    models_stat.append([\"Average\", np.sum(average_accuracy) / len(average_accuracy) * 100])\n",
        "    # print([\"Average\", np.sum(average_accuracy) / len(average_accuracy) * 100])\n",
        "\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    for i in range(len(models_stat)): \n",
        "        x_data.append(models_stat[i][0])\n",
        "        y_data.append(models_stat[i][1])\n",
        "    _, ax = plt.subplots()\n",
        "    ax.bar(x_data, y_data, color = '#539caf', align = 'center')\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.set_xlabel(\"Models\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0S-IjO1jG74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "e87c11d2-a75d-4758-b165-1bdeefe5927b"
      },
      "source": [
        "global_test(modelsDir, \"/content/gdrive/My Drive/pneumonia/test/\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ApnTjzjHcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def global_predict(dir_models, dir_image):\n",
        "\n",
        "    images_stat = []\n",
        "    num_mod = 0\n",
        "\n",
        "    name_image = []\n",
        "    images = []\n",
        "\n",
        "    for files in os.listdir(dir_image):\n",
        "        if files.endswith('.jpg') or files.endswith('.jpeg'):\n",
        "            imagePath = dir_image + files\n",
        "            name_image.append(files)\n",
        "            img = Image.open(imagePath)\n",
        "            img = img.resize((size, size)).convert(\"RGB\")\n",
        "            data = np.array(img.getdata())\n",
        "            img = 2 * (data.reshape((img.size[0], img.size[1], 3)).astype(np.float32) / 255) - 1\n",
        "            images.append(img)\n",
        "\n",
        "    out = h5py.File(\"/content/gdrive/My Drive/pneumonia/tmptest.h5\", \"a\")\n",
        "    out.create_dataset(\"imagesTmp\", data=images)\n",
        "    out.close()\n",
        "\n",
        "    dset = h5py.File(\"/content/gdrive/My Drive/pneumonia/tmptest.h5\", \"r\")\n",
        "    imagesTmp = dset[\"imagesTmp\"][:]\n",
        "    os.remove(\"/content/gdrive/My Drive/pneumonia/tmptest.h5\")\n",
        "\n",
        "    for file_model in os.listdir(dir_models):\n",
        "      print(\"==================================================\\nCurrent model is: \", file_model)\n",
        "      num_mod += 1\n",
        "      dir_model = dir_models + \"/\" + file_model\n",
        "  \n",
        "      model = models.load_model(dir_model)\n",
        "      predictions = model.predict(imagesTmp)\n",
        "      predictions = predictions.reshape(1, -1)[0]\n",
        "\n",
        "      accuracy_array = []\n",
        "\n",
        "      for i in range(0, len(predictions), 2):\n",
        "          accuracy_array.append(predictions[i + 1])\n",
        "      images_stat.append(accuracy_array)\n",
        "      print(accuracy_array)\n",
        "    result = []    \n",
        "\n",
        "    for i in range(len(name_image)):\n",
        "        sum_ac = 0\n",
        "        for j in range(num_mod):\n",
        "            sum_ac += images_stat[j][i]  \n",
        "        result.append([name_image[i], sum_ac / num_mod * 100])\n",
        "    print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yENubwpjKDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "092334cb-6444-4483-d232-42e489c94fa5"
      },
      "source": [
        "global_predict(modelsDir, \"/content/gdrive/My Drive/pneumonia/predict/\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Current model is:  DenseNet201.h5\n",
            "[0.80515814, 0.31375903, 0.9218358, 0.21440962, 0.27970856, 0.9933089, 0.9997603, 0.99996066, 0.9999448, 0.9999738, 0.99963653]\n",
            "==================================================\n",
            "Current model is:  InceptionV3.h5\n",
            "[0.40310085, 0.10136545, 0.06597551, 0.73889625, 0.07067555, 0.999403, 0.999979, 0.9999894, 0.99999845, 0.9999951, 0.9999865]\n",
            "==================================================\n",
            "Current model is:  Xception.h5\n",
            "[0.75224245, 0.9093114, 0.42268726, 0.3660663, 0.67556673, 0.9520684, 0.99998724, 0.9876858, 0.99970955, 0.992174, 0.99277765]\n",
            "==================================================\n",
            "Current model is:  InceptionResNetV2.h5\n",
            "[0.46895933, 0.38373956, 0.10561333, 0.6876495, 0.10917726, 0.99903405, 0.9977284, 0.999183, 0.9996574, 0.9999672, 0.99894005]\n",
            "==================================================\n",
            "Current model is:  ResNet152V2.h5\n",
            "[0.6803595, 0.4239296, 0.19710515, 0.64173937, 0.23886223, 0.9997682, 0.99869365, 0.9995278, 0.9996364, 0.9993544, 0.9971312]\n",
            "==================================================\n",
            "Current model is:  VGG16.h5\n",
            "[0.86695546, 0.15812369, 0.32251948, 0.46605688, 0.09625916, 0.9991066, 0.9999708, 0.99998987, 0.9999335, 0.9999831, 0.99993014]\n",
            "==================================================\n",
            "Current model is:  MobileNetV2.h5\n",
            "[0.18382409, 0.07634474, 0.25555715, 0.2261674, 0.03265051, 0.99678373, 0.99986184, 0.9999821, 0.9998324, 0.99991584, 0.9998671]\n",
            "[['IM-0001-0001.jpeg', 59.43713997091565], ['IM-0003-0001.jpeg', 33.80819261074066], ['IM-0005-0001.jpeg', 32.73276665381023], ['IM-0006-0001.jpeg', 47.72836161511285], ['IM-0007-0001.jpeg', 21.470000222325325], ['person1_virus_6.jpeg', 99.13532648767743], ['person1_virus_7.jpeg', 99.94258965764728], ['person1_virus_8.jpeg', 99.80455211230687], ['person1_virus_9.jpeg', 99.98160685811725], ['person1_virus_11.jpeg', 99.87662093979972], ['person1_virus_12.jpeg', 99.83241728373936]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}